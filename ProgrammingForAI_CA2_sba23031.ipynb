{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b5fb48-67c3-46db-a7a6-4a856c796b0c",
   "metadata": {},
   "source": [
    "## CA2\n",
    "\n",
    "sba23031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5162da-4729-41b6-83b6-817ef1450e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 19:56:21.368726: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "import random\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e0e81-b333-4e01-84a8-5b53d1144541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"glass_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fc624-46b7-414d-a1de-4c41a2813264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10323a6-e7af-4844-9154-468387dd03ef",
   "metadata": {},
   "source": [
    "Our dataset has 214 rows and 11 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f2b7b9-eaef-4004-ab32-02ff312a5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a3b9a-63b7-4f5c-ba99-169c721abcab",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b174fc7-6644-4b51-86f3-41328fb65a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde2a03-cd14-4c9e-b9b1-2b43737d7059",
   "metadata": {},
   "source": [
    "After reading the data and checking it loaded successfully the first thing to do is to call df.describe()\n",
    "\n",
    "This function from the pandas library will give a comprehensive summary of the basic statistics of each column.\n",
    "\n",
    "The values for ID don't really matter as it is just an identification column.\n",
    "\n",
    "The \"type\" column also is pretty understandable as it is the classification of 1-7 with 4 missing.\n",
    "\n",
    "The rest of the columns give more valuable information. The first thing that sticks out is that the columns \"ba\" and \"fe\" have a very low mean and a lot of 0.0 values. This could effect the data preparation and how the model is built. Those fields might could potentially not contribute much to the classification.\n",
    "\n",
    "I don't have domain knowledge so maybe this is still valuable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8698d2-2d0c-4266-9698-2c3c5ce1757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='plasma')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c1fd5-e44c-44d5-af62-c7fc32834c49",
   "metadata": {},
   "source": [
    "A correlation matrix will give an idea of how much one feature can effect the other.\n",
    "\n",
    "From this there doesn't seem to be any great correlation to the glass type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d8e8e-fdb5-4cd0-ba23-2a1a65774889",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['ri', 'na', 'mg', 'al', 'si', 'k', 'ca', 'ba', 'fe']\n",
    "\n",
    "for feature in df.columns[:-1]:  # Exclude the target variable\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x='type', y=feature, data=df, palette='viridis')\n",
    "    plt.title(f\"Box Plot of {feature} by Glass Type\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e064cb-c291-4548-8da2-82ddebb506ad",
   "metadata": {},
   "source": [
    "The box plots above show the distribution of each checmical with regards to the glass type. \n",
    "\n",
    "Again it shows some useful information in regards to \"ba\" and \"fa\". Iron seems to be very much in class types 1,2, and 3. While barium is mainly in type 7 but it has some outliers in regards 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1bd7ac-e4b6-49c4-a09b-aac21cd3f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(x='type', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a32a5e2-6c8c-4420-8dd6-250b531ce234",
   "metadata": {},
   "source": [
    "Next thing is to get an idea of the distribution of the target variable. The absence of glass type 4 made me suspicous there there could be unbalanced data. \n",
    "\n",
    "From the bar chart above we can see that the target variable leads more towards types 1 and 2. This imbalance needs to be sorted when we split the data for training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e113ee2-133d-4959-b7d2-d2061821b2a4",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513c3c60-4649-446b-acc3-d90f605ed0c2",
   "metadata": {},
   "source": [
    "After exploring the data we now need to clean it before applying any model. \n",
    "\n",
    "The main thing is check if there are any null or missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efee006-2389-486d-aeb8-739479023f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0435b1-b791-432f-8549-ee1c2479b57c",
   "metadata": {},
   "source": [
    "Straight away this dataset has no null values. This would not usually be the case but at this is a small dataset containing mostly numerics it is not that ouf of the ordinary.\n",
    "\n",
    "But since this is numerical we can plot how much of each variable has a value of 0.00. Like mentioned above we don't have domain knowledge of this area so the zero values can't be taken as invalid. They need to be kept into consideration for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693cab8-a350-460c-bee6-eaabdf30753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_counts = (df == 0).sum()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "zero_counts.plot(kind='bar')\n",
    "plt.title('Number of Zero Values per Column')\n",
    "plt.ylabel('Number of Zero Values')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf125ee-786d-4dd7-93ad-2709be12dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f98148-5f30-4979-b0d2-f16e83f1e449",
   "metadata": {},
   "source": [
    "The ID column is just a unique identifier for each row and is not necessary for this project. The valus are all too unique and don't provide anything for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b50d1-bdc9-4350-9d7a-62219d941dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"id\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d893d-b31a-484e-98c6-88dc7af36fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280503d-aa8f-4aae-a529-6304d2e96a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52001a79-71ca-4082-ad73-f5aaa797b7fb",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5006f51-3e06-412b-9833-ee792539a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['type'])\n",
    "y = df['type'] - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d6c074-5047-47d6-80ad-5d7f6357be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5334b-364e-4d1f-bc48-f284cc161bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=7)\n",
    "\n",
    "print(X_train_scaled.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71957adc-afd3-4e87-b78c-2ccaf1eaaf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for Python\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set random seed for TensorFlow\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6217f4aa-8ce6-4d37-ada6-29ce9495cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(9, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "# Hidden layers\n",
    "\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train_one_hot, epochs=50, verbose=0, batch_size=20)\n",
    "\n",
    "model.evaluate(X_test_scaled, y_test_one_hot)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417f4dc-7b2c-4501-94f8-37adbfb1cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b35d1d-ae5d-4478-b2c0-1f7beacfbcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da3dbe-b667-404d-88a6-532c5c64a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad5ff9-872e-41c9-8a49-ad8a6083ec24",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb21266-a7ac-4e15-9b55-1241d6985a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_1_units': [32, 64, 128],\n",
    "    'hidden_layer_2_units': [16, 32, 64],\n",
    "    'batch_size': [10, 20, 32],\n",
    "    'epochs': [50, 100, 150],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0fcdd8-369b-4183-879b-c8f29418cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hidden_layer_1_units, hidden_layer_2_units, batch_size, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_1_units, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(hidden_layer_2_units, activation='relu'))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b820b-dc6a-4254-930e-a7b96ff01df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_classifier = KerasClassifier(build_fn=build_model, verbose=0)\n",
    "# grid_search = GridSearchCV(estimator=keras_classifier, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fcb173-4b8c-4179-b19c-02ac16b8748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_result.best_params_\n",
    "best_model = grid_result.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7814203-cdac-452b-b1eb-411731f39c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best model: {best_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d1a0df-8605-43d3-834c-f90fd1e48727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
